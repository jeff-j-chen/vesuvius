{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 399713\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.config import Config\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "config = Config()\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # (B, 1, H, W)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # (B, 1, H, W)\n",
    "        attn = torch.cat([avg_out, max_out], dim=1)  # (B, 2, H, W)\n",
    "        attn = self.conv(attn)  # (B, 1, H, W)\n",
    "        attn = self.sigmoid(attn)  # (B, 1, H, W)\n",
    "        return x * attn  # Apply attention\n",
    "\n",
    "class InkDetector(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super(InkDetector, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Input: (B, 1, 8, 32, 32)\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 4, 4), padding=1, bias=False),  # (B, 32, 6, 31, 31)\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(config.model.conv1_drop),\n",
    "            \n",
    "            nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=1, bias=False),  # (B, 64, 4, 31, 31)\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2)),  # (B, 64, 6, 15, 15)\n",
    "            \n",
    "            nn.Conv3d(64, 96, kernel_size=(4, 3, 3), padding=1, bias=False),  # (B, 96, 1, 15, 15)\n",
    "            nn.BatchNorm3d(96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(config.model.conv2_drop),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2)),  # (B, 96, 5, 7, 7)\n",
    "            \n",
    "            nn.Conv3d(96, 128, kernel_size=(1, 3, 3), padding=1, bias=False),  # (B, 128, 1, 7, 7)\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(config.model.conv1_drop),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2)),  # (B, 128, 1, 3, 3)\n",
    "            nn.Dropout3d(config.model.conv2_drop),\n",
    "            \n",
    "            nn.AdaptiveAvgPool3d(1)  # (B, 128, 1, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(config.model.fc1_drop),\n",
    "            nn.Linear(64, 32, bias=False),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(config.model.fc2_drop),\n",
    "            nn.Linear(32, 1)  # Keep bias for final output layer\n",
    "        )\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def hook(module, input, output):\n",
    "            self.activations[module] = output.detach()\n",
    "\n",
    "        for layer in self.features:\n",
    "            if not isinstance(layer, (nn.Dropout3d, nn.BatchNorm3d)):\n",
    "                layer.register_forward_hook(hook)\n",
    "        for layer in self.classifier:\n",
    "            if not isinstance(layer, (nn.Dropout, nn.BatchNorm1d)):\n",
    "                layer.register_forward_hook(hook)\n",
    "\n",
    "\n",
    "model = InkDetector(config).to('cuda')  # Instantiate your model (replace InkDetector with your class)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 430723\n"
     ]
    }
   ],
   "source": [
    "class CBAM3D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=3):\n",
    "        super(CBAM3D, self).__init__()\n",
    "\n",
    "        # Channel Attention\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool3d(1)\n",
    "\n",
    "        self.shared_mlp = nn.Sequential(\n",
    "            nn.Conv3d(channels, channels // reduction, kernel_size=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(channels // reduction, channels, kernel_size=1, bias=False)\n",
    "        )\n",
    "        self.sigmoid_channel = nn.Sigmoid()\n",
    "\n",
    "        # Spatial Attention\n",
    "        self.conv_spatial = nn.Conv3d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid_spatial = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # --- Channel Attention ---\n",
    "        avg_out = self.shared_mlp(self.avg_pool(x))\n",
    "        max_out = self.shared_mlp(self.max_pool(x))\n",
    "        channel_attn = self.sigmoid_channel(avg_out + max_out)\n",
    "        x = x * channel_attn\n",
    "\n",
    "        # --- Spatial Attention ---\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        spatial_attn = self.sigmoid_spatial(self.conv_spatial(torch.cat([avg_out, max_out], dim=1)))\n",
    "        x = x * spatial_attn\n",
    "\n",
    "        return x\n",
    "\n",
    "class InkDetector(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super(InkDetector, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 4, 4), padding=1, bias=False),  # (B, 32, 8, 31, 31)\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            CBAM3D(32),\n",
    "            nn.Dropout3d(config.model.conv1_drop),\n",
    "\n",
    "            nn.Conv3d(32, 96, kernel_size=(3, 3, 3), padding=1, bias=False),  # (B, 96, 8, 31, 31)\n",
    "            nn.BatchNorm3d(96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            CBAM3D(96),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),  # (B, 96, 4, 15, 15)\n",
    "\n",
    "            nn.Conv3d(96, 128, kernel_size=(3, 3, 3), padding=1, bias=False),  # (B, 128, 4, 15, 15)\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            CBAM3D(128),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),  # (B, 128, 2, 7, 7)\n",
    "\n",
    "            nn.AdaptiveAvgPool3d(1)  # (B, 128, 1, 1, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),  # (B, 128)\n",
    "            nn.Linear(128, 64, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(config.model.fc1_drop),\n",
    "\n",
    "            nn.Linear(64, 32, bias=False),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(config.model.fc2_drop),\n",
    "\n",
    "            nn.Linear(32, 1)  # Output: (B, 1)\n",
    "        )\n",
    "        self.activations = {}\n",
    "        self._register_hooks()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def hook(module, input, output):\n",
    "            self.activations[module] = output.detach()\n",
    "\n",
    "        for layer in self.features:\n",
    "            if not isinstance(layer, (nn.Dropout3d, nn.BatchNorm3d)):\n",
    "                layer.register_forward_hook(hook)\n",
    "        for layer in self.classifier:\n",
    "            if not isinstance(layer, (nn.Dropout, nn.BatchNorm1d)):\n",
    "                layer.register_forward_hook(hook)\n",
    "\n",
    "model = InkDetector(config).to('cuda')  # Instantiate your model (replace InkDetector with your class)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11174, 3340, 3440)\n"
     ]
    }
   ],
   "source": [
    "import vesuvius\n",
    "from vesuvius import Volume\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scroll = Volume(type=\"Scroll\", scroll_id=3, energy=53, resolution=7.91)\n",
    "print(scroll.shape(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while initializing the Volume class: URL not found for scroll: 4, energy: 53, resolution: 7.91, segment: 20231210132040\n",
      "Load the canonical scroll 1 with Volume(type=\"scroll\", scroll_id=1, energy=54, resolution=7.91)\n",
      "If loading another part of the same physical scroll use for instance Volume(type=\"scroll\", scroll_id=\"1b\", energy=54, resolution=7.91)\n",
      "Load a segment (e.g. 20230827161847) with Volume(type=\"segment\", scroll_id=1, energy=54, resolution=7.91, segment_id=20230827161847)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "URL not found for scroll: 4, energy: 53, resolution: 7.91, segment: 20231210132040",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m files \u001b[38;5;241m=\u001b[39m vesuvius\u001b[38;5;241m.\u001b[39mlist_files()\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# vol =files['4']['53']['7.91']['volume']\u001b[39;00m\n",
      "\u001b[0;32m----> 8\u001b[0m segment \u001b[38;5;241m=\u001b[39m \u001b[43mVolume\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscroll_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menergy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m53\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7.91\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20231210132040\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# segment.shape(0)\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/vesuvius/volume.py:184\u001b[0m, in \u001b[0;36mVolume.__init__\u001b[0;34m(self, type, scroll_id, energy, resolution, segment_id, cache, cache_pool, normalize, verbose, domain, path)\u001b[0m\n",
      "\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m verbose\n",
      "\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdl.ash2txt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_url_from_yaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_ome_metadata()\n",
      "\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_data()\n",
      "\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/vesuvius/volume.py:305\u001b[0m, in \u001b[0;36mVolume.get_url_from_yaml\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mURL not found for scroll: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscroll_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, energy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menergy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, resolution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mURL not found for scroll: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscroll_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, energy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menergy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, resolution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, segment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mURL not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: URL not found for scroll: 4, energy: 53, resolution: 7.91, segment: 20231210132040"
     ]
    }
   ],
   "source": [
    "import vesuvius\n",
    "from vesuvius import Volume\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
