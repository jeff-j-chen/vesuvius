{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 399713\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.config import Config\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "config = Config()\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # (B, 1, H, W)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # (B, 1, H, W)\n",
    "        attn = torch.cat([avg_out, max_out], dim=1)  # (B, 2, H, W)\n",
    "        attn = self.conv(attn)  # (B, 1, H, W)\n",
    "        attn = self.sigmoid(attn)  # (B, 1, H, W)\n",
    "        return x * attn  # Apply attention\n",
    "\n",
    "class InkDetector(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super(InkDetector, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Input: (B, 1, 8, 32, 32)\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 4, 4), padding=1, bias=False),  # (B, 32, 6, 31, 31)\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(config.model.conv1_drop),\n",
    "            \n",
    "            nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=1, bias=False),  # (B, 64, 4, 31, 31)\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2)),  # (B, 64, 6, 15, 15)\n",
    "            \n",
    "            nn.Conv3d(64, 96, kernel_size=(4, 3, 3), padding=1, bias=False),  # (B, 96, 1, 15, 15)\n",
    "            nn.BatchNorm3d(96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(config.model.conv2_drop),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2)),  # (B, 96, 5, 7, 7)\n",
    "            \n",
    "            nn.Conv3d(96, 128, kernel_size=(1, 3, 3), padding=1, bias=False),  # (B, 128, 1, 7, 7)\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(config.model.conv1_drop),\n",
    "            nn.MaxPool3d(kernel_size=(1, 2, 2)),  # (B, 128, 1, 3, 3)\n",
    "            nn.Dropout3d(config.model.conv2_drop),\n",
    "            \n",
    "            nn.AdaptiveAvgPool3d(1)  # (B, 128, 1, 1, 1)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 64, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(config.model.fc1_drop),\n",
    "            nn.Linear(64, 32, bias=False),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(config.model.fc2_drop),\n",
    "            nn.Linear(32, 1)  # Keep bias for final output layer\n",
    "        )\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def hook(module, input, output):\n",
    "            self.activations[module] = output.detach()\n",
    "\n",
    "        for layer in self.features:\n",
    "            if not isinstance(layer, (nn.Dropout3d, nn.BatchNorm3d)):\n",
    "                layer.register_forward_hook(hook)\n",
    "        for layer in self.classifier:\n",
    "            if not isinstance(layer, (nn.Dropout, nn.BatchNorm1d)):\n",
    "                layer.register_forward_hook(hook)\n",
    "\n",
    "\n",
    "model = InkDetector(config).to('cuda')  # Instantiate your model (replace InkDetector with your class)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 430723\n"
     ]
    }
   ],
   "source": [
    "class CBAM3D(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=3):\n",
    "        super(CBAM3D, self).__init__()\n",
    "\n",
    "        # Channel Attention\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool3d(1)\n",
    "\n",
    "        self.shared_mlp = nn.Sequential(\n",
    "            nn.Conv3d(channels, channels // reduction, kernel_size=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(channels // reduction, channels, kernel_size=1, bias=False)\n",
    "        )\n",
    "        self.sigmoid_channel = nn.Sigmoid()\n",
    "\n",
    "        # Spatial Attention\n",
    "        self.conv_spatial = nn.Conv3d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid_spatial = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # --- Channel Attention ---\n",
    "        avg_out = self.shared_mlp(self.avg_pool(x))\n",
    "        max_out = self.shared_mlp(self.max_pool(x))\n",
    "        channel_attn = self.sigmoid_channel(avg_out + max_out)\n",
    "        x = x * channel_attn\n",
    "\n",
    "        # --- Spatial Attention ---\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        spatial_attn = self.sigmoid_spatial(self.conv_spatial(torch.cat([avg_out, max_out], dim=1)))\n",
    "        x = x * spatial_attn\n",
    "\n",
    "        return x\n",
    "\n",
    "class InkDetector(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super(InkDetector, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=(3, 4, 4), padding=1, bias=False),  # (B, 32, 8, 31, 31)\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            CBAM3D(32),\n",
    "            nn.Dropout3d(config.model.conv1_drop),\n",
    "\n",
    "            nn.Conv3d(32, 96, kernel_size=(3, 3, 3), padding=1, bias=False),  # (B, 96, 8, 31, 31)\n",
    "            nn.BatchNorm3d(96),\n",
    "            nn.ReLU(inplace=True),\n",
    "            CBAM3D(96),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),  # (B, 96, 4, 15, 15)\n",
    "\n",
    "            nn.Conv3d(96, 128, kernel_size=(3, 3, 3), padding=1, bias=False),  # (B, 128, 4, 15, 15)\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            CBAM3D(128),\n",
    "            nn.MaxPool3d(kernel_size=(2, 2, 2)),  # (B, 128, 2, 7, 7)\n",
    "\n",
    "            nn.AdaptiveAvgPool3d(1)  # (B, 128, 1, 1, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),  # (B, 128)\n",
    "            nn.Linear(128, 64, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(config.model.fc1_drop),\n",
    "\n",
    "            nn.Linear(64, 32, bias=False),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(config.model.fc2_drop),\n",
    "\n",
    "            nn.Linear(32, 1)  # Output: (B, 1)\n",
    "        )\n",
    "        self.activations = {}\n",
    "        self._register_hooks()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def hook(module, input, output):\n",
    "            self.activations[module] = output.detach()\n",
    "\n",
    "        for layer in self.features:\n",
    "            if not isinstance(layer, (nn.Dropout3d, nn.BatchNorm3d)):\n",
    "                layer.register_forward_hook(hook)\n",
    "        for layer in self.classifier:\n",
    "            if not isinstance(layer, (nn.Dropout, nn.BatchNorm1d)):\n",
    "                layer.register_forward_hook(hook)\n",
    "\n",
    "model = InkDetector(config).to('cuda')  # Instantiate your model (replace InkDetector with your class)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
